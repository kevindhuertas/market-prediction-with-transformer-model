{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOUMPFQhUY4XVqCr3cxtZW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevindhuertas/market-prediction-with-transformer-model/blob/main/main_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install TA-Lib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5GNGng1Wv4U",
        "outputId": "a49cc3ff-59f1-4bfe-a542-47754edb3c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting TA-Lib\n",
            "  Using cached TA-Lib-0.5.2.tar.gz (372 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from TA-Lib) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from TA-Lib) (1.26.4)\n",
            "Building wheels for collected packages: TA-Lib\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for TA-Lib \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for TA-Lib (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for TA-Lib\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build TA-Lib\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (TA-Lib)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y build-essential\n",
        "!apt-get install -y libta-lib0-dev\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knYz3iHradbi",
        "outputId": "30f60ea0-9487-4e01-ccae-7d44dddc115c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package libta-lib0-dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yfinance as yf\n",
        "import pandas_ta as ta  # Librería para indicadores técnicos\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ],
      "metadata": {
        "id": "J4HvSATSdthK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# ANÁLISIS DE DATOS: APPLE, AMAZON Y OTRAS EMPRESAS\n",
        "# =============================================\n",
        "\n",
        "# ---------\n",
        "# Librerías\n",
        "# ---------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yfinance as yf\n",
        "import pandas_ta as ta  # Librería para indicadores técnicos\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Para visualizar las gráficas en el notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# 1. Descarga de Datos de Varias Empresas con Velas de 5 Minutos\n",
        "# -----------------------------------------------------------------------\n",
        "# Definimos los símbolos y el periodo\n",
        "symbols = [\"AAPL\"]\n",
        "period = \"3mo\"  # Periodo de 1 mes\n",
        "interval = \"15m\"  # Intervalo de 5 minutos\n",
        "\n",
        "# Descargamos los datos\n",
        "stocks_data = {}\n",
        "for symbol in symbols:\n",
        "    try:\n",
        "        print(f\"Descargando datos para {symbol}...\")\n",
        "        stocks_data[symbol] = yf.download(symbol, period=period, interval=interval, progress=False)\n",
        "    except Exception as e:\n",
        "        print(f\"Error descargando datos para {symbol}: {e}\")\n",
        "\n",
        "# Concatenamos todos los DataFrames en uno solo\n",
        "df_all = pd.concat(stocks_data.values(), axis=0)\n",
        "\n",
        "# Verificamos si se descargaron datos correctamente\n",
        "if df_all.empty:\n",
        "    print(\"No se pudieron descargar los datos. Verifique el rango de fechas y el intervalo.\")\n",
        "else:\n",
        "    # Aseguramos que las columnas estén en un formato plano\n",
        "    if isinstance(df_all.columns, pd.MultiIndex):\n",
        "        df_all.columns = df_all.columns.get_level_values(0)\n",
        "\n",
        "    # Revisamos las primeras filas del DataFrame combinado\n",
        "    print(\"Primeras filas del DataFrame combinado:\")\n",
        "    display(df_all.head())\n",
        "\n",
        "    # -----------------------------------------------------------------------\n",
        "    # 2. Agregar Indicadores Técnicos con pandas_ta\n",
        "    # -----------------------------------------------------------------------\n",
        "\n",
        "    def add_technical_indicators_with_pandas_ta(df):\n",
        "        df = df.copy()\n",
        "\n",
        "        # Indicadores de tendencia\n",
        "        df.ta.sma(length=50, append=True)  # Media móvil simple (50)\n",
        "        df.ta.sma(length=100, append=True)  # Media móvil simple (100)\n",
        "        df.ta.ema(length=50, append=True)  # Media móvil exponencial (50)\n",
        "        df.ta.ema(length=100, append=True)  # Media móvil exponencial (100)\n",
        "\n",
        "        # Indicadores de momentum\n",
        "        df.ta.rsi(length=14, append=True)  # Relative Strength Index (14)\n",
        "        df.ta.macd(append=True)  # Moving Average Convergence Divergence\n",
        "        df.ta.stoch(append=True)  # Stochastic Oscillator (K, D)\n",
        "\n",
        "        # Indicadores de volatilidad\n",
        "        df.ta.atr(length=14, append=True)  # Average True Range (14)\n",
        "        df.ta.bbands(length=20, append=True)  # Bollinger Bands (20, 2)\n",
        "\n",
        "        # Indicadores de volumen\n",
        "        df.ta.obv(append=True)  # On-Balance Volume\n",
        "        df.ta.cmf(length=20, append=True)  # Chaikin Money Flow (20)\n",
        "\n",
        "        return df\n",
        "\n",
        "    # Agregamos los indicadores técnicos al DataFrame combinado\n",
        "    df_all = add_technical_indicators_with_pandas_ta(df_all)\n",
        "\n",
        "    print(\"Primeras filas del DataFrame combinado con indicadores técnicos:\")\n",
        "    display(df_all.head())\n",
        "\n",
        "    # -----------------------------------------------------------------------\n",
        "    # 3. Limpieza y Normalización de Datos\n",
        "    # -----------------------------------------------------------------------\n",
        "\n",
        "    # 3.1 Eliminar filas con valores nulos\n",
        "    print(\"Valores nulos antes de la limpieza:\")\n",
        "    print(df_all.isnull().sum())\n",
        "\n",
        "    df_all = df_all.dropna()\n",
        "\n",
        "    print(\"Valores nulos después de la limpieza:\")\n",
        "    print(df_all.isnull().sum())\n",
        "\n",
        "    # 3.2 Normalización de columnas numéricas\n",
        "    scaler = MinMaxScaler()\n",
        "    columns_to_normalize = [\n",
        "        \"Open\", \"High\", \"Low\", \"Close\", \"Volume\",\n",
        "        \"SMA_50\", \"SMA_100\", \"EMA_50\", \"EMA_100\",\n",
        "        \"RSI_14\", \"MACD_12_26_9\", \"MACDs_12_26_9\",\n",
        "        \"BBL_20_2.0\", \"BBM_20_2.0\", \"BBU_20_2.0\",\n",
        "        \"ATRr_14\", \"CMF_20\"\n",
        "    ]\n",
        "\n",
        "    # Escalamos solo las columnas relevantes\n",
        "    df_all[columns_to_normalize] = scaler.fit_transform(df_all[columns_to_normalize])\n",
        "\n",
        "    # Imprimir datos después de la normalización\n",
        "    print(\"Datos después de la normalización:\")\n",
        "    display(df_all[columns_to_normalize].head())\n",
        "\n",
        "    # 3.3 Separar las características y etiquetas\n",
        "    features = df_all[columns_to_normalize]\n",
        "    df_all[\"Target\"] = df_all[\"Close\"].shift(-3) > df_all[\"Close\"]  # Etiqueta para predicción de 3 velas\n",
        "    targets = df_all[\"Target\"]\n",
        "\n",
        "    # 3.4 Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(features, targets, test_size=0.3, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    print(\"Tamaños de los conjuntos:\")\n",
        "    print(f\"Entrenamiento: {X_train.shape}, Validación: {X_val.shape}, Prueba: {X_test.shape}\")\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Observaciones\n",
        "# -----------------------------------------------------------------------\n",
        "# - Se utilizan velas de 5 minutos para el análisis con un periodo de 1 mes.\n",
        "# - Los datos de múltiples empresas se combinan en un único DataFrame sin columnas adicionales.\n",
        "# - Se eliminaron las filas con valores nulos.\n",
        "# - Las características fueron normalizadas al rango [0, 1].\n",
        "# - Los datos fueron divididos en conjuntos de entrenamiento, validación y prueba.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1ZAdPFlcIPS",
        "outputId": "1453e325-0c49-4a6c-adaa-f210731aa0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargando datos para AAPL...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['AAPL']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (period=3mo) (Yahoo error = \"15m data not available for startTime=1727309085 and endTime=1735344285. The requested range must be within the last 60 days.\")')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No se pudieron descargar los datos. Verifique el rango de fechas y el intervalo.\n"
          ]
        }
      ]
    }
  ]
}